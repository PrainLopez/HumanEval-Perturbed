{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login(\"\")"
   ],
   "id": "47e04ff7acb898be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "pipe(messages)"
   ],
   "id": "fec5c0711ab6705"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:19:09.499712Z",
     "start_time": "2025-04-22T01:19:04.999060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "human_eval = load_dataset(\"openai/openai_humaneval\")\n",
    "# human_eval = load_dataset()\n",
    "\n",
    "print(human_eval)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "human_eval[\"test\"][0][\"prompt\"]\n",
   "id": "631783760b06661f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d3caae71ce81b50a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "55b11ab227f80f2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\")"
   ],
   "id": "33a88f092b810362",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:33:51.250632Z",
     "start_time": "2025-04-22T12:12:31.922429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from openai import OpenAI\n",
    "from transformers import pipeline\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "MODEL_NAME = \"Llama-3.1-8B\"\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=\"AIzaSyAINgg3E9YxU6SYGOe3Eva0IurNmtzbNoo\",\n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "# )\n",
    "#\n",
    "# MODEL_NAME = model\n",
    "#\n",
    "# # encapsulate openai API into a function only requires messages as input\n",
    "# def pipe(messages):\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=MODEL_NAME,\n",
    "#         n=1,\n",
    "#         messages=messages\n",
    "#     )\n",
    "#     return response\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"Hi Gemini\"\n",
    "#     }\n",
    "# ]\n",
    "# print(pipe(messages))\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=f\"meta-llama/{MODEL_NAME}\")\n",
    "\n",
    "outputs = []\n",
    "for sample in human_eval[\"test\"]:\n",
    "    begin_time = time.perf_counter()\n",
    "\n",
    "    prompt = sample[\"prompt\"]\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    response = pipe(messages)\n",
    "    outputs.append({\n",
    "        \"task_id\": sample[\"task_id\"],\n",
    "        \"prompt\": prompt,\n",
    "        'canonical_solution': sample[\"canonical_solution\"],\n",
    "        'test': sample[\"test\"],\n",
    "        'entry_point': sample[\"entry_point\"],\n",
    "        # \"response\": response[0][\"generated_text\"]\n",
    "        \"response\": response.choices[0].message.content\n",
    "    })\n",
    "    with open(f\"lab/{MODEL_NAME}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(outputs, f)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    # print current progress\n",
    "    serial = int(sample[\"task_id\"].split(\"/\")[-1]) + 1\n",
    "    print(\"Current: {}\\t{}/{}\\t Last: {:.3f}s\".format(sample[\"task_id\"], serial, len(human_eval['test']), end_time-begin_time), end=\"\\r\")\n",
    "    # wait 5 seconds to avoid rate limiting\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"{MODEL_NAME} with HumanEval done.\")\n"
   ],
   "id": "39ebb4d5251a011b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-1.5-pro with HumanEval done.t: 2.767s\n"
     ]
    },
    {
     "ename": "ProcessLookupError",
     "evalue": "[Errno 3] No such process",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mProcessLookupError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[53]\u001B[39m\u001B[32m, line 68\u001B[39m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m     67\u001B[39m pid = \u001B[32m48124\u001B[39m \u001B[38;5;66;03m# caffeinate 进程ID\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m os.kill(pid, signal.SIGINT)\n",
      "\u001B[31mProcessLookupError\u001B[39m: [Errno 3] No such process"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "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",
   "id": "7f7e7de72d0f8953"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T12:34:51.478698Z",
     "start_time": "2025-04-22T12:34:51.476028Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(outputs))",
   "id": "67f9ad4795270bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# dump outputs to Llama-3.2-1B-Instruct.pkl\n",
    "import pickle\n",
    "\n",
    "with open(\"Llama-3.2-1B-Instruct.pkl\", \"wb\") as f:\n",
    "    pickle.dump(outputs, f)"
   ],
   "id": "7355549b60003e84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:30:43.880300Z",
     "start_time": "2025-04-22T01:30:43.871555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "# load outputs from Llama-3.2-1B-Instruct.pkl\n",
    "with open(\"gemini-2.0-flash-lite.pkl\", \"rb\") as f:\n",
    "    outputs = pickle.load(f)\n",
    "\n",
    "outputs[0]"
   ],
   "id": "91e96518c73b4821",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/0',\n",
       " 'prompt': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n",
       " 'canonical_solution': '    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n',\n",
       " 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\",\n",
       " 'entry_point': 'has_close_elements',\n",
       " 'response': '```python\\nfrom typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    n = len(numbers)\\n    for i in range(n):\\n        for j in range(i + 1, n):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n```'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:41:10.381079Z",
     "start_time": "2025-04-22T01:41:10.376501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "code = outputs[0][\"response\"]\n",
    "# strip other text from code\n",
    "code = code.split(\"```python\")[1].split(\"```\")[0]\n",
    "\n",
    "test_code = outputs[0][\"test\"]\n",
    "\n",
    "executes = code + \"\\n\" + test_code + \"\\n\" + \"check({})\".format(outputs[0][\"entry_point\"])\n",
    "exec(executes)\n",
    "print(\"PASS!\")"
   ],
   "id": "14b859bcfc272bb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS!\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:39:29.194977Z",
     "start_time": "2025-04-22T01:39:29.188939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run code as python script\n",
    "code = \"\"\"\n",
    "from typing import List\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    for idx, elem in enumerate(numbers):\n",
    "        for idx2, elem2 in enumerate(numbers):\n",
    "            if idx != idx2:\n",
    "                distance = abs(elem - elem2)\n",
    "                if distance < threshold:\n",
    "                    return False    # False to trigger AssertionError\n",
    "\n",
    "    return False\n",
    "\"\"\"\n",
    "test_code = outputs[0][\"test\"]\n",
    "print(test_code)"
   ],
   "id": "e4da8dd6747821e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METADATA = {\n",
      "    'author': 'jt',\n",
      "    'dataset': 'test'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\n",
      "    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b8376ec83b86881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57e5bf18905c67f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9beb94e43188e48f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9ba803ee69fd541",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "53bfb9b36168492",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
