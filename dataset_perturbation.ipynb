{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T15:54:02.091587Z",
     "start_time": "2025-07-13T15:53:59.894505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datasets as ds\n",
    "import pandas as pd\n",
    "\n",
    "human_eval = ds.load_dataset(\"openai/openai_humaneval\")\n",
    "\n",
    "print(human_eval)"
   ],
   "id": "458499321571340d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:11:38.890945Z",
     "start_time": "2025-07-06T14:11:38.872813Z"
    }
   },
   "cell_type": "code",
   "source": "human_eval[\"test\"].to_csv(\"human_eval.csv\", index=False)",
   "id": "fc790c8770d09c26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bff253ef1cd146d0aac4fff7e54fa8ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "196170"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:15:45.915378Z",
     "start_time": "2025-07-06T14:15:45.901130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rename all the functions in the dataset to \"test\"\n",
    "\n",
    "import re\n",
    "\n",
    "def lambda_rename (row: dict):\n",
    "    fun_name: str = row[\"entry_point\"]\n",
    "    rename = \"test\"\n",
    "    regex_pattern = rf\"(def |>>> )({fun_name})(\\()\"\n",
    "    replacement_str = rf\"\\1{rename}\\3\"\n",
    "\n",
    "    regex_id = r\"HumanEval\"\n",
    "    replacement_id = r\"HumanEvalRenamed\"\n",
    "\n",
    "    renamed_id = re.sub(regex_id, replacement_id, row[\"task_id\"])\n",
    "    renamed_prompt = re.sub(regex_pattern, replacement_str, row[\"prompt\"])\n",
    "    row[\"task_id\"] = renamed_id\n",
    "    row[\"entry_point\"] = rename\n",
    "    row[\"prompt\"] = renamed_prompt\n",
    "    return row\n",
    "\n",
    "renamed_set = human_eval[\"test\"].map(lambda_rename)\n",
    "\n",
    "human_eval[\"renamed\"] = renamed_set\n",
    "\n",
    "print(human_eval)"
   ],
   "id": "88ca185e81445aa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "    renamed: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T14:15:51.345708Z",
     "start_time": "2025-07-06T14:15:51.326481Z"
    }
   },
   "cell_type": "code",
   "source": "human_eval[\"renamed\"].to_csv(\"human_eval_renamed.csv\", index=False)",
   "id": "c6de43d8bdf19934",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "253fe4257ba045169a980843948b08d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "193303"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T16:34:36.301211Z",
     "start_time": "2025-07-13T16:34:36.277571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "interference = pd.read_csv(\"data/nonsense.csv\").sample(164)"
   ],
   "id": "e94b6cbb75a974fb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T16:36:00.055365Z",
     "start_time": "2025-07-13T16:35:59.949028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lambda_interfered (row: dict):\n",
    "    serial = int(row[\"task_id\"].split(\"/\")[-1])\n",
    "\n",
    "\n",
    "    regex_pattern = r'\"\"\"(?!.*\"\"\")'\n",
    "    replace_str = f'Tip:\\n\\t{interference.values[serial][0]}\\n\"\"\"'\n",
    "\n",
    "    interfered_prompt = re.sub(regex_pattern, replace_str, row[\"prompt\"], count=1, flags=re.DOTALL)\n",
    "    row[\"prompt\"] = interfered_prompt\n",
    "\n",
    "    return row\n",
    "\n",
    "# for i in range(len(human_eval[\"test\"])):\n",
    "human_eval[\"interfered\"] = human_eval[\"test\"].map(lambda_interfered)\n",
    "\n",
    "print(human_eval)"
   ],
   "id": "32b40282907dd36a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaf4ef9e69234648a57abcc3a499526c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "    interfered: Dataset({\n",
      "        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T16:36:00.706447Z",
     "start_time": "2025-07-13T16:36:00.685991Z"
    }
   },
   "cell_type": "code",
   "source": "human_eval[\"interfered\"].to_csv(\"data/human_eval_interfered.csv\", index=False)",
   "id": "cd599556fcb67cf9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f4d9e1bbc5b4d8a8b3a5d8f2e10fab9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "206009"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b5b662a16c2085d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
